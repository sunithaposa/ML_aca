{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abalone (from Spanish Abulón) are shellfish, a genus of gastropods. Abalone are known by their colorful \"pearlescent\" inside shell. This is also called ear-shell, ormer in Guernsey, abalone in South Africa, and pāua in New Zealand.\n",
    "Abalone Data Set :\n",
    "Abstract: Predict the age of abalone from physical measurements.\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "Predicting the age of abalone from physical measurements. The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age. Further information, such as weather patterns and location (hence food availability) may be required to solve the problem. \n",
    "\n",
    "From the original data examples with missing values were removed (the majority having the predicted value missing), and the ranges of the continuous values have been scaled for use with an ANN (by dividing by 200).\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Given is the attribute name, attribute type, the measurement unit and a brief description. The number of rings is the value to predict: either as a continuous value or as a classification problem. \n",
    "\n",
    "Name / Data Type / Measurement Unit / Description \n",
    "----------------------------- \n",
    "Sex / nominal / -- / M, F, and I (infant) \n",
    "Length / continuous / mm / Longest shell measurement \n",
    "Diameter\t/ continuous / mm / perpendicular to length \n",
    "Height / continuous / mm / with meat in shell \n",
    "Whole weight / continuous / grams / whole abalone \n",
    "Shucked weight / continuous\t/ grams / weight of meat \n",
    "Viscera weight / continuous / grams / gut weight (after bleeding) \n",
    "Shell weight / continuous / grams / after being dried \n",
    "Rings / integer / -- / +1.5 gives the age in years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "columns=['Sex','Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weight','Rings']\n",
    "abalone_data=pd.read_csv('C:\\\\Users\\\\Lenovo\\\\ML\\\\EX\\\\abalone\\\\abalone.data',names=columns)\n",
    "abalone_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.523992</td>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.139516</td>\n",
       "      <td>0.828742</td>\n",
       "      <td>0.359367</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>0.238831</td>\n",
       "      <td>9.933684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.099240</td>\n",
       "      <td>0.041827</td>\n",
       "      <td>0.490389</td>\n",
       "      <td>0.221963</td>\n",
       "      <td>0.109614</td>\n",
       "      <td>0.139203</td>\n",
       "      <td>3.224169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length     Diameter       Height  Whole weight  Shucked weight  \\\n",
       "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
       "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
       "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
       "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
       "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
       "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
       "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
       "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
       "\n",
       "       Viscera weight  Shell weight        Rings  \n",
       "count     4177.000000   4177.000000  4177.000000  \n",
       "mean         0.180594      0.238831     9.933684  \n",
       "std          0.109614      0.139203     3.224169  \n",
       "min          0.000500      0.001500     1.000000  \n",
       "25%          0.093500      0.130000     8.000000  \n",
       "50%          0.171000      0.234000     9.000000  \n",
       "75%          0.253000      0.329000    11.000000  \n",
       "max          0.760000      1.005000    29.000000  "
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex               0\n",
      "Length            0\n",
      "Diameter          0\n",
      "Height            0\n",
      "Whole weight      0\n",
      "Shucked weight    0\n",
      "Viscera weight    0\n",
      "Shell weight      0\n",
      "Rings             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for null values\n",
    "print (abalone_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986812</td>\n",
       "      <td>0.827554</td>\n",
       "      <td>0.925261</td>\n",
       "      <td>0.897914</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>0.897706</td>\n",
       "      <td>0.556720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter</th>\n",
       "      <td>0.986812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833684</td>\n",
       "      <td>0.925452</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.899724</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.574660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>0.827554</td>\n",
       "      <td>0.833684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819221</td>\n",
       "      <td>0.774972</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.557467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whole weight</th>\n",
       "      <td>0.925261</td>\n",
       "      <td>0.925452</td>\n",
       "      <td>0.819221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969405</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.955355</td>\n",
       "      <td>0.540390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shucked weight</th>\n",
       "      <td>0.897914</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.774972</td>\n",
       "      <td>0.969405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931961</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>0.420884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viscera weight</th>\n",
       "      <td>0.903018</td>\n",
       "      <td>0.899724</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.931961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907656</td>\n",
       "      <td>0.503819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shell weight</th>\n",
       "      <td>0.897706</td>\n",
       "      <td>0.905330</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.955355</td>\n",
       "      <td>0.882617</td>\n",
       "      <td>0.907656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rings</th>\n",
       "      <td>0.556720</td>\n",
       "      <td>0.574660</td>\n",
       "      <td>0.557467</td>\n",
       "      <td>0.540390</td>\n",
       "      <td>0.420884</td>\n",
       "      <td>0.503819</td>\n",
       "      <td>0.627574</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Length  Diameter    Height  Whole weight  Shucked weight  \\\n",
       "Length          1.000000  0.986812  0.827554      0.925261        0.897914   \n",
       "Diameter        0.986812  1.000000  0.833684      0.925452        0.893162   \n",
       "Height          0.827554  0.833684  1.000000      0.819221        0.774972   \n",
       "Whole weight    0.925261  0.925452  0.819221      1.000000        0.969405   \n",
       "Shucked weight  0.897914  0.893162  0.774972      0.969405        1.000000   \n",
       "Viscera weight  0.903018  0.899724  0.798319      0.966375        0.931961   \n",
       "Shell weight    0.897706  0.905330  0.817338      0.955355        0.882617   \n",
       "Rings           0.556720  0.574660  0.557467      0.540390        0.420884   \n",
       "\n",
       "                Viscera weight  Shell weight     Rings  \n",
       "Length                0.903018      0.897706  0.556720  \n",
       "Diameter              0.899724      0.905330  0.574660  \n",
       "Height                0.798319      0.817338  0.557467  \n",
       "Whole weight          0.966375      0.955355  0.540390  \n",
       "Shucked weight        0.931961      0.882617  0.420884  \n",
       "Viscera weight        1.000000      0.907656  0.503819  \n",
       "Shell weight          0.907656      1.000000  0.627574  \n",
       "Rings                 0.503819      0.627574  1.000000  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#checking the correlation\n",
    "correlationMatrix = abalone_data.corr() #computes correlation between 2 columns \n",
    "correlationMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=abalone_data.iloc[:,:-1].values\n",
    "y=abalone_data.iloc[:,8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "X[:,0]=labelencoder.fit_transform(X[:,0])\n",
    "onehotencoder=OneHotEncoder(categorical_features=[3])\n",
    "X=onehotencoder.fit_transform(X).toarray()\n",
    "X=X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#normalize X\\nfrom sklearn import preprocessing\\nnormalized_X = preprocessing.normalize(X)\\nnormalized_X'"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#normalize X\n",
    "from sklearn import preprocessing\n",
    "normalized_X = preprocessing.normalize(X)\n",
    "normalized_X'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.30, random_state = 4)\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3290319906916449"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting the model\n",
    "y_pred=regressor.predict(X_test)\n",
    "regressor.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32489351661172783\n",
      "0.29993380206628817\n",
      "0.3148549860633636\n",
      "0.32313448580929927\n",
      "0.3328401697882677\n",
      "0.27691761916790225\n",
      "0.3290319906916449\n",
      "0.2882533821242105\n",
      "0.317297565945562\n",
      "0.3158062728059582\n",
      "0.3020867458901476\n",
      "0.35228297239299866\n",
      "0.32311427496949796\n",
      "0.30088293642171515\n",
      "0.3324808658680033\n",
      "0.2818701372046377\n",
      "0.323999389095039\n",
      "0.29925779116158424\n"
     ]
    }
   ],
   "source": [
    "#splitting the data set\n",
    "for i in range(1,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.30, random_state = i)\n",
    "    y_train = y_train.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "    regressor=LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred=regressor.predict(X_test)\n",
    "    print(regressor.score(X_train, y_train))\n",
    "    print(regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATSMODELS ###\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((4177, 1)).astype(int), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 9)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>newRings</td>     <th>  R-squared:         </th> <td>   0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   242.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 12 May 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:16:26</td>     <th>  Log-Likelihood:    </th> <td> -2026.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4177</td>      <th>  AIC:               </th> <td>   4070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4168</td>      <th>  BIC:               </th> <td>   4127.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0134</td> <td>    0.048</td> <td>   -0.279</td> <td> 0.780</td> <td>   -0.108</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0294</td> <td>    0.394</td> <td>   -0.075</td> <td> 0.941</td> <td>   -0.801</td> <td>    0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0014</td> <td>    0.007</td> <td>    0.187</td> <td> 0.852</td> <td>   -0.013</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -1.3357</td> <td>    0.324</td> <td>   -4.128</td> <td> 0.000</td> <td>   -1.970</td> <td>   -0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.6932</td> <td>    0.394</td> <td>    4.295</td> <td> 0.000</td> <td>    0.920</td> <td>    2.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    1.1675</td> <td>    0.130</td> <td>    8.984</td> <td> 0.000</td> <td>    0.913</td> <td>    1.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -2.3125</td> <td>    0.146</td> <td>  -15.818</td> <td> 0.000</td> <td>   -2.599</td> <td>   -2.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.3636</td> <td>    0.231</td> <td>   -1.573</td> <td> 0.116</td> <td>   -0.817</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    1.2429</td> <td>    0.201</td> <td>    6.197</td> <td> 0.000</td> <td>    0.850</td> <td>    1.636</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>273.299</td> <th>  Durbin-Watson:     </th> <td>   1.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 219.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.478</td>  <th>  Prob(JB):          </th> <td>1.72e-48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.407</td>  <th>  Cond. No.          </th> <td>    160.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               newRings   R-squared:                       0.318\n",
       "Model:                            OLS   Adj. R-squared:                  0.316\n",
       "Method:                 Least Squares   F-statistic:                     242.7\n",
       "Date:                Sun, 12 May 2019   Prob (F-statistic):               0.00\n",
       "Time:                        10:16:26   Log-Likelihood:                -2026.0\n",
       "No. Observations:                4177   AIC:                             4070.\n",
       "Df Residuals:                    4168   BIC:                             4127.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0134      0.048     -0.279      0.780      -0.108       0.081\n",
       "x1            -0.0294      0.394     -0.075      0.941      -0.801       0.742\n",
       "x2             0.0014      0.007      0.187      0.852      -0.013       0.016\n",
       "x3            -1.3357      0.324     -4.128      0.000      -1.970      -0.701\n",
       "x4             1.6932      0.394      4.295      0.000       0.920       2.466\n",
       "x5             1.1675      0.130      8.984      0.000       0.913       1.422\n",
       "x6            -2.3125      0.146    -15.818      0.000      -2.599      -2.026\n",
       "x7            -0.3636      0.231     -1.573      0.116      -0.817       0.090\n",
       "x8             1.2429      0.201      6.197      0.000       0.850       1.636\n",
       "==============================================================================\n",
       "Omnibus:                      273.299   Durbin-Watson:                   1.585\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              219.966\n",
       "Skew:                           0.478   Prob(JB):                     1.72e-48\n",
       "Kurtosis:                       2.407   Cond. No.                         160.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_opt=X[:,[0,1,2,3,4,5,6,7,8]]\n",
    "regressor_stat=sm.OLS(endog =Y, exog = X_opt).fit()\n",
    "\n",
    "regressor_stat.summary()\n",
    "# print the R-squared value for the model\n",
    "#regressor_stat.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7711276035432129"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "'''Simple Logistic Regression Model\n",
    "No of Classes : 2\n",
    "1 - Rings > 10\n",
    "0 - Rings <= 10'''\n",
    "'''Creating New Target Variable '''\n",
    "abalone_data['newRings'] = np.where(abalone_data['Rings'] > 10,1,0)\n",
    "\n",
    "'''Learning Features and Predicting Features'''\n",
    "X = abalone_data.drop(['newRings','Rings','Sex'], axis = 1)\n",
    "\n",
    "\n",
    "Y=abalone_data['newRings']\n",
    "\n",
    "\n",
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X, Y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "model.score(X, Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7563451776649747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       923\n",
      "           1       0.67      0.52      0.59       456\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1379\n",
      "   macro avg       0.73      0.70      0.71      1379\n",
      "weighted avg       0.75      0.76      0.75      1379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# predict class labels for the test set\n",
    "predicted = model2.predict(X_test)\n",
    "predicted\n",
    "\n",
    "# generate class probabilities\n",
    "probs = model2.predict_proba(X_test)\n",
    "probs\n",
    "\n",
    "# generate evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, predicted))\n",
    "#print(metrics.roc_auc_score(y_test, probs[:,7]))\n",
    "\n",
    "\n",
    "#print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.80741627, 0.73803828, 0.76167665, 0.7760479 , 0.74730539]),\n",
       " 0.7660968971148613)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), X, Y, scoring='accuracy', cv=5)\n",
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 NN Score: 100.00%\n",
      "80 0.9998868616027304\n",
      "81 0.9998756553707333\n",
      "82 0.9998772078627538\n",
      "83 0.9998715880911324\n",
      "84 0.9998611613638949\n",
      "85 0.9998644089389124\n",
      "86 0.9998644429071281\n",
      "87 0.9998437333078354\n",
      "88 0.9998396490312061\n",
      "89 0.9998395094613038\n",
      "90 0.9998430561040724\n",
      "91 0.9998215603019293\n",
      "92 0.9998242570465561\n",
      "93 0.9998079387351242\n",
      "94 0.9998120034087924\n",
      "95 0.9998094057408027\n",
      "96 0.9998087341071799\n",
      "97 0.9998095234219467\n",
      "98 0.9997994037097077\n",
      "99 0.9998034356930958\n",
      "100 0.9998030879949061\n",
      "101 0.9997899451452894\n",
      "102 0.9997868005658764\n",
      "103 0.9997665224816166\n",
      "104 0.9997709908475843\n",
      "105 0.9997696857407755\n",
      "106 0.9997635132318758\n",
      "107 0.9997567521038029\n",
      "108 0.9997499998794112\n",
      "109 0.9997178887791857\n",
      "110 0.9996905014757466\n",
      "111 0.9996811613599824\n",
      "112 0.9996797772761741\n",
      "113 0.9996636096511841\n",
      "114 0.9996362069893889\n",
      "115 0.999630862377965\n",
      "116 0.9996040846999417\n",
      "117 0.9995914365425056\n",
      "118 0.9995910375066103\n",
      "119 0.9995738196462302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors = 11)  # n_neighbors means k\n",
    "X=abalone_data.iloc[:,1:-1].values\n",
    "y=abalone_data.iloc[:,8].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "knn.fit(X_train, y_train)\n",
    "prediction = knn.predict(X_test)\n",
    "\n",
    "print(\"{} NN Score: {:.2f}%\".format(2, knn.score(X_test, y_test)*100))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "scoreList = []\n",
    "for i in range(80,120):\n",
    "    knn2 = KNeighborsRegressor(n_neighbors = i)  # n_neighbors means k\n",
    "    knn2.fit(X_train, y_train)\n",
    "    scoreList.append(knn2.score(X_test, y_test))\n",
    "    print(i,knn2.score(X_test, y_test))\n",
    "    #print(\"Accuracy is \", accuracy_score(y_test,y_pred)*100,\"% for K-Value:\",i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[923   0]\n",
      " [  0 456]]\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X=abalone_data.iloc[:,1:-1].values\n",
    "y=abalone_data.iloc[:,8].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "classifier = DecisionTreeRegressor( random_state = 20)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classifier.score(X_train, y_train))\n",
    "print(classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7933284989122552\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "# Fit the training model\n",
    "model.fit(X_train,y_train)\n",
    "# Predicted outcomes\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Actual Expected Outvomes\n",
    "expected = y_test\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
